{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'app'\n",
      "/app\n"
     ]
    }
   ],
   "source": [
    "%cd app \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE      dataset\t\t models\t\t\t scripts.sh\tweights\n",
      "README.md    dummy.ipynb\t options\t\t test_sirs.py\n",
      "__pycache__  engine.py\t\t reflection-removal.zip  tools\n",
      "checkpoints  eval_sirs.py\t requirements.txt\t train_sirs.py\n",
      "data\t     mamba-container.sh  runner.sh\t\t util\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "base_dir: ./dataset/reflection-removal/\n",
      "batchSize: 1\n",
      "checkpoints_dir: ./checkpoints\n",
      "dataset: sirs_dataset\n",
      "debug: False\n",
      "debug_eval: False\n",
      "display_freq: 100\n",
      "display_id: 0\n",
      "display_port: 8097\n",
      "display_single_pane_ncols: 0\n",
      "display_winsize: 256\n",
      "eval_freq: 1\n",
      "fineSize: 224,224\n",
      "finetune: False\n",
      "fixed_lr: 0\n",
      "gan_type: rasgan\n",
      "gpu_ids: [0]\n",
      "graph: False\n",
      "hyper: False\n",
      "if_align: True\n",
      "inet: mdsrnet_m\n",
      "init_lr: 0.01\n",
      "init_type: edsr\n",
      "isTrain: True\n",
      "lambda_gan: 0.01\n",
      "lambda_rec: 0.2\n",
      "lambda_vgg: 0.01\n",
      "loadSize: 224,336,448\n",
      "loss: losses\n",
      "lr: 0.0001\n",
      "max_dataset_size: None\n",
      "model: dsrnet_model_sirs\n",
      "nEpochs: 1\n",
      "nThreads: 8\n",
      "name: dsrnet_l\n",
      "no_flip: False\n",
      "no_html: False\n",
      "no_log: False\n",
      "no_verbose: False\n",
      "print_freq: 100\n",
      "r_pixel_weight: 1.0\n",
      "real20_size: 420\n",
      "resize_or_crop: resize_and_crop\n",
      "resume: False\n",
      "resume_epoch: None\n",
      "save_epoch_freq: 1\n",
      "save_freq: 1\n",
      "seed: 2018\n",
      "select: None\n",
      "selected: None\n",
      "serial_batches: False\n",
      "start_now: False\n",
      "supp_eval: False\n",
      "testr: False\n",
      "unaligned_loss: vgg\n",
      "update_html_freq: 1000\n",
      "vgg_layer: 31\n",
      "wd: 0\n",
      "weight_dir: \n",
      "weight_path: None\n",
      "which_model_D: disc_vgg\n",
      "-------------- End ----------------\n",
      "Namespace(base_dir='./dataset/reflection-removal/', batchSize=1, checkpoints_dir='./checkpoints', dataset='sirs_dataset', debug=False, debug_eval=False, display_freq=100, display_id=0, display_port=8097, display_single_pane_ncols=0, display_winsize=256, eval_freq=1, fineSize='224,224', finetune=False, fixed_lr=0, gan_type='rasgan', gpu_ids=[0], graph=False, hyper=False, if_align=True, inet='mdsrnet_m', init_lr=0.01, init_type='edsr', isTrain=True, lambda_gan=0.01, lambda_rec=0.2, lambda_vgg=0.01, loadSize='224,336,448', loss='losses', lr=0.0001, max_dataset_size=None, model='dsrnet_model_sirs', nEpochs=1, nThreads=8, name='dsrnet_l', no_flip=False, no_html=False, no_log=False, no_verbose=False, print_freq=100, r_pixel_weight=1.0, real20_size=420, resize_or_crop='resize_and_crop', resume=False, resume_epoch=None, save_epoch_freq=1, save_freq=1, seed=2018, select=None, selected=None, serial_batches=False, start_now=False, supp_eval=False, testr=False, unaligned_loss='vgg', update_html_freq=1000, vgg_layer=31, wd=0, weight_dir='', weight_path=None, which_model_D='disc_vgg')\n",
      "[i] using a fusion dataset: 7932 [7643, 89, 200] imgs fused with ratio [0.6, 0.2, 0.2]\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[i] initialization method [edsr]\n",
      "--------------------- Model ---------------------\n",
      "##################### NetG #####################\n",
      "Network Architecture:  MDSRNet\n",
      "Total number of parameters: 102884006,98.118Mb\n",
      "The size of receptive field: 346\n",
      "create web directory ./checkpoints/dsrnet_l/web...\n",
      "[i] set learning rate to 0.0001\n",
      "random_seed:  2018\n",
      "\n",
      "Epoch: 0\n",
      "Traceback (most recent call last):.................................]  Step: 1s109ms | Tot: 1s109ms | Ex: 0.0494 | I_P: 0.2176 | R_P: 0.1879 | Re: 0.1448 | VGG: 0.0814 | lr: 0.0001 | seed: 2018.0000  2/7932 \n",
      "  File \"train_sirs.py\", line 112, in <module>\n",
      "    engine.train(train_dataloader_fusion)\n",
      "  File \"/app/engine.py\", line 47, in train\n",
      "    model.optimize_parameters(**kwargs)\n",
      "  File \"/app/models/dsrnet_model_sirs.py\", line 214, in optimize_parameters\n",
      "    self.backward_G()\n",
      "  File \"/app/models/dsrnet_model_sirs.py\", line 194, in backward_G\n",
      "    self.loss_exclu, self.loss_recons = self.get_loss(self.output_t, self.output_r, self.output_rr)\n",
      "  File \"/app/models/dsrnet_model_sirs.py\", line 185, in get_loss\n",
      "    loss_r_pixel = self.loss_dic['r_pixel'](out_r, self.target_r)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/app/models/losses.py\", line 35, in forward\n",
      "    total_loss += loss(predict, target) * weight\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/app/models/losses.py\", line 23, in forward\n",
      "    return self.loss(predict_gradx, target_gradx) + self.loss(predict_grady, target_grady)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py\", line 101, in forward\n",
      "    return F.l1_loss(input, target, reduction=self.reduction)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 3261, in l1_loss\n",
      "    return torch._C._nn.l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 15.72 GiB total capacity; 13.66 GiB already allocated; 896.00 KiB free; 15.03 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=1, python3 train_sirs.py --inet mdsrnet_m --model dsrnet_model_sirs --dataset sirs_dataset --loss losses  --name dsrnet_l  --lambda_vgg 0.01 --lambda_rec 0.2 --if_align --seed 2018 --base_dir \"./dataset/reflection-removal/\" --nEpochs 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "base_dir: ./dataset/reflection-removal/\n",
      "batchSize: 1\n",
      "checkpoints_dir: ./checkpoints\n",
      "dataset: sirs_dataset\n",
      "debug: False\n",
      "debug_eval: False\n",
      "display_freq: 100\n",
      "display_id: 0\n",
      "display_port: 8097\n",
      "display_single_pane_ncols: 0\n",
      "display_winsize: 256\n",
      "eval_freq: 1\n",
      "fineSize: 224,224\n",
      "finetune: False\n",
      "fixed_lr: 0\n",
      "gan_type: rasgan\n",
      "gpu_ids: [0]\n",
      "graph: False\n",
      "hyper: False\n",
      "if_align: True\n",
      "inet: dsrnet_l\n",
      "init_lr: 0.01\n",
      "init_type: edsr\n",
      "isTrain: True\n",
      "lambda_gan: 0.01\n",
      "lambda_rec: 0.2\n",
      "lambda_vgg: 0.01\n",
      "loadSize: 224,336,448\n",
      "loss: losses\n",
      "lr: 0.0001\n",
      "max_dataset_size: None\n",
      "model: dsrnet_model_sirs\n",
      "nEpochs: 1\n",
      "nThreads: 8\n",
      "name: dsrnet_l\n",
      "no_flip: False\n",
      "no_html: False\n",
      "no_log: False\n",
      "no_verbose: False\n",
      "print_freq: 100\n",
      "r_pixel_weight: 1.0\n",
      "real20_size: 420\n",
      "resize_or_crop: resize_and_crop\n",
      "resume: False\n",
      "resume_epoch: None\n",
      "save_epoch_freq: 1\n",
      "save_freq: 1\n",
      "seed: 2018\n",
      "select: None\n",
      "selected: None\n",
      "serial_batches: False\n",
      "start_now: False\n",
      "supp_eval: False\n",
      "testr: False\n",
      "unaligned_loss: vgg\n",
      "update_html_freq: 1000\n",
      "vgg_layer: 31\n",
      "wd: 0\n",
      "weight_dir: \n",
      "weight_path: None\n",
      "which_model_D: disc_vgg\n",
      "-------------- End ----------------\n",
      "Namespace(base_dir='./dataset/reflection-removal/', batchSize=1, checkpoints_dir='./checkpoints', dataset='sirs_dataset', debug=False, debug_eval=False, display_freq=100, display_id=0, display_port=8097, display_single_pane_ncols=0, display_winsize=256, eval_freq=1, fineSize='224,224', finetune=False, fixed_lr=0, gan_type='rasgan', gpu_ids=[0], graph=False, hyper=False, if_align=True, inet='dsrnet_l', init_lr=0.01, init_type='edsr', isTrain=True, lambda_gan=0.01, lambda_rec=0.2, lambda_vgg=0.01, loadSize='224,336,448', loss='losses', lr=0.0001, max_dataset_size=None, model='dsrnet_model_sirs', nEpochs=1, nThreads=8, name='dsrnet_l', no_flip=False, no_html=False, no_log=False, no_verbose=False, print_freq=100, r_pixel_weight=1.0, real20_size=420, resize_or_crop='resize_and_crop', resume=False, resume_epoch=None, save_epoch_freq=1, save_freq=1, seed=2018, select=None, selected=None, serial_batches=False, start_now=False, supp_eval=False, testr=False, unaligned_loss='vgg', update_html_freq=1000, vgg_layer=31, wd=0, weight_dir='', weight_path=None, which_model_D='disc_vgg')\n",
      "[i] using a fusion dataset: 7932 [7643, 89, 200] imgs fused with ratio [0.6, 0.2, 0.2]\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[i] initialization method [edsr]\n",
      "--------------------- Model ---------------------\n",
      "##################### NetG #####################\n",
      "Network Architecture:  DSRNet\n",
      "Total number of parameters: 124602022,118.830Mb\n",
      "The size of receptive field: 338\n",
      "create web directory ./checkpoints/dsrnet_l/web...\n",
      "[i] set learning rate to 0.0001\n",
      "random_seed:  2018\n",
      "\n",
      "Epoch: 0\n",
      "^C>................................................................]  Step: 957ms | Tot: 29s250ms | Ex: 0.0349 | I_P: 0.0899 | R_P: 0.0712 | Re: 0.0491 | VGG: 0.0549 | lr: 0.0001 | seed: 2018.0000  31/7932 2 32 \n",
      "Traceback (most recent call last):\n",
      "  File \"train_sirs.py\", line 112, in <module>\n",
      "    engine.train(train_dataloader_fusion)\n",
      "  File \"/app/engine.py\", line 47, in train\n",
      "    model.optimize_parameters(**kwargs)\n",
      "  File \"/app/models/dsrnet_model_sirs.py\", line 216, in optimize_parameters\n",
      "    self.optimizer_G.step()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 140, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 23, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 234, in step\n",
      "    adam(params_with_grad,\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 300, in adam\n",
      "    func(params,\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 410, in _single_tensor_adam\n",
      "    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!CUDA_VISIBLE_DEVICES=1, python3 train_sirs.py --inet dsrnet_l --model dsrnet_model_sirs --dataset sirs_dataset --loss losses  --name dsrnet_l  --lambda_vgg 0.01 --lambda_rec 0.2 --if_align --seed 2018 --base_dir \"./dataset/reflection-removal/\" --nEpochs 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "base_dir: ./dataset/reflection-removal/\n",
      "batchSize: 1\n",
      "checkpoints_dir: ./checkpoints\n",
      "dataset: sirs_dataset\n",
      "debug: False\n",
      "debug_eval: False\n",
      "display_freq: 100\n",
      "display_id: 0\n",
      "display_port: 8097\n",
      "display_single_pane_ncols: 0\n",
      "display_winsize: 256\n",
      "eval_freq: 1\n",
      "fineSize: 224,224\n",
      "finetune: False\n",
      "fixed_lr: 0\n",
      "gan_type: rasgan\n",
      "gpu_ids: [0]\n",
      "graph: False\n",
      "hyper: False\n",
      "if_align: True\n",
      "inet: mdsrnet\n",
      "init_lr: 0.01\n",
      "init_type: edsr\n",
      "isTrain: True\n",
      "lambda_gan: 0.01\n",
      "lambda_rec: 0.2\n",
      "lambda_vgg: 0.01\n",
      "loadSize: 224,336,448\n",
      "loss: losses\n",
      "lr: 0.0001\n",
      "max_dataset_size: None\n",
      "model: dsrnet_model_sirs\n",
      "nEpochs: 1\n",
      "nThreads: 8\n",
      "name: dsrnet_l\n",
      "no_flip: False\n",
      "no_html: False\n",
      "no_log: False\n",
      "no_verbose: False\n",
      "print_freq: 100\n",
      "r_pixel_weight: 1.0\n",
      "real20_size: 420\n",
      "resize_or_crop: resize_and_crop\n",
      "resume: False\n",
      "resume_epoch: None\n",
      "save_epoch_freq: 1\n",
      "save_freq: 1\n",
      "seed: 2018\n",
      "select: None\n",
      "selected: None\n",
      "serial_batches: False\n",
      "start_now: False\n",
      "supp_eval: False\n",
      "testr: False\n",
      "unaligned_loss: vgg\n",
      "update_html_freq: 1000\n",
      "vgg_layer: 31\n",
      "wd: 0\n",
      "weight_dir: \n",
      "weight_path: None\n",
      "which_model_D: disc_vgg\n",
      "-------------- End ----------------\n",
      "Namespace(base_dir='./dataset/reflection-removal/', batchSize=1, checkpoints_dir='./checkpoints', dataset='sirs_dataset', debug=False, debug_eval=False, display_freq=100, display_id=0, display_port=8097, display_single_pane_ncols=0, display_winsize=256, eval_freq=1, fineSize='224,224', finetune=False, fixed_lr=0, gan_type='rasgan', gpu_ids=[0], graph=False, hyper=False, if_align=True, inet='mdsrnet', init_lr=0.01, init_type='edsr', isTrain=True, lambda_gan=0.01, lambda_rec=0.2, lambda_vgg=0.01, loadSize='224,336,448', loss='losses', lr=0.0001, max_dataset_size=None, model='dsrnet_model_sirs', nEpochs=1, nThreads=8, name='dsrnet_l', no_flip=False, no_html=False, no_log=False, no_verbose=False, print_freq=100, r_pixel_weight=1.0, real20_size=420, resize_or_crop='resize_and_crop', resume=False, resume_epoch=None, save_epoch_freq=1, save_freq=1, seed=2018, select=None, selected=None, serial_batches=False, start_now=False, supp_eval=False, testr=False, unaligned_loss='vgg', update_html_freq=1000, vgg_layer=31, wd=0, weight_dir='', weight_path=None, which_model_D='disc_vgg')\n",
      "[i] using a fusion dataset: 7932 [7643, 89, 200] imgs fused with ratio [0.6, 0.2, 0.2]\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[i] initialization method [edsr]\n",
      "--------------------- Model ---------------------\n",
      "##################### NetG #####################\n",
      "Network Architecture:  MDSRNet\n",
      "Total number of parameters: 262450854,250.293Mb\n",
      "The size of receptive field: 410\n",
      "create web directory ./checkpoints/dsrnet_l/web...\n",
      "[i] set learning rate to 0.0001\n",
      "random_seed:  2018\n",
      "\n",
      "Epoch: 0\n",
      "Traceback (most recent call last):.................................]  Step: 13s545ms | Tot: 0ms | Ex: 0.0410 | I_P: 0.2466 | R_P: 0.2301 | Re: 0.1742 | VGG: 0.0624 | lr: 0.0001 | seed: 2018.0000  1/7932 \n",
      "  File \"train_sirs.py\", line 112, in <module>\n",
      "    engine.train(train_dataloader_fusion)\n",
      "  File \"/app/engine.py\", line 47, in train\n",
      "    model.optimize_parameters(**kwargs)\n",
      "  File \"/app/models/dsrnet_model_sirs.py\", line 211, in optimize_parameters\n",
      "    self.forward()\n",
      "  File \"/app/models/dsrnet_model_sirs.py\", line 201, in forward\n",
      "    output_t, output_r, output_rr = self.network(input_i,\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/app/models/arch/dsrnet.py\", line 423, in forward\n",
      "    rr = self.lrm(x, y)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/app/models/arch/lrm.py\", line 183, in forward\n",
      "    fs = self.blocks_merge(torch.cat([ft, fr], dim=1))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\", line 204, in forward\n",
      "    input = module(input)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/app/models/arch/lrm.py\", line 161, in forward\n",
      "    x = self.block1(inp)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\", line 204, in forward\n",
      "    input = module(input)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/app/models/arch/lrm.py\", line 61, in forward\n",
      "    return x * self.ca(x)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 15.72 GiB total capacity; 14.66 GiB already allocated; 49.62 MiB free; 15.06 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python3 train_sirs.py --inet mdsrnet --model dsrnet_model_sirs --dataset sirs_dataset --loss losses  --name dsrnet_l  --lambda_vgg 0.01 --lambda_rec 0.2 --if_align --seed 2018 --base_dir \"./dataset/reflection-removal/\" --nEpochs 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE      dataset\t\t models\t\t\t test_sirs.py\n",
      "README.md    dummy.ipynb\t options\t\t tools\n",
      "__pycache__  engine.py\t\t reflection-removal.zip  train_sirs.py\n",
      "checkpoints  eval_sirs.py\t requirements.txt\t util\n",
      "data\t     mamba-container.sh  scripts.sh\t\t weights\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LayerNorm((3,), eps=1e-05, elementwise_affine=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mamba_ssm import Mamba\n",
    "import torch\n",
    "\n",
    "\n",
    "# torch.rand()\n",
    "\n",
    "m = Mamba(\n",
    "    # This module uses roughly 3 * expand * d_model^2 parameters\n",
    "            d_model=3, # Model dimension d_model\n",
    "            d_state=16,  # SSM state expansion factor\n",
    "            d_conv=4,    # Local convolution width\n",
    "            expand=2,    # Block expansion factor\n",
    "        )\n",
    "\n",
    "ll = torch.nn.LayerNorm(normalized_shape=3)\n",
    "\n",
    "m.to(\"cuda\")\n",
    "ll.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 144, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((8,3,12,12)).to(\"cuda\")\n",
    "# m(ll(x.reshape(8, -1 , 3)))\n",
    "m(x.reshape(8, -1 , 3)).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE      dataset\t\t models\t\t\t test_sirs.py\n",
      "README.md    dummy.ipynb\t options\t\t tools\n",
      "__pycache__  engine.py\t\t reflection-removal.zip  train_sirs.py\n",
      "checkpoints  eval_sirs.py\t requirements.txt\t util\n",
      "data\t     mamba-container.sh  scripts.sh\t\t weights\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play around\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Mamba' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmamba_ssm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Mamba\n\u001b[1;32m      6\u001b[0m m \u001b[38;5;241m=\u001b[39m MuGIBlock(\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m m2 \u001b[38;5;241m=\u001b[39m \u001b[43mMuGIMBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m m1 \u001b[38;5;241m=\u001b[39m ImageMamba(\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m ma \u001b[38;5;241m=\u001b[39m Mamba(\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# This module uses roughly 3 * expand * d_model^2 parameters\u001b[39;00m\n\u001b[1;32m     11\u001b[0m             d_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, \u001b[38;5;66;03m# Model dimension d_model\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m             expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,    \u001b[38;5;66;03m# Block expansion factor\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/app/models/arch/dsrnet.py:119\u001b[0m, in \u001b[0;36mMuGIMBlock.__init__\u001b[0;34m(self, c, shared_b)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, c, shared_b\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock1 \u001b[38;5;241m=\u001b[39m DualStreamSeq(\n\u001b[1;32m    118\u001b[0m         DualStreamBlock(\n\u001b[0;32m--> 119\u001b[0m             \u001b[43mImageMamba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;66;03m# replace layerNorm and conv2d blocks\u001b[39;00m\n\u001b[1;32m    120\u001b[0m             nn\u001b[38;5;241m.\u001b[39mConv2d(c, c \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, groups\u001b[38;5;241m=\u001b[39mc) \u001b[38;5;66;03m# c * 2 -> c for inputs\u001b[39;00m\n\u001b[1;32m    121\u001b[0m         ),\n\u001b[1;32m    122\u001b[0m         DualStreamGate(),\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;66;03m# DualStreamBlock(ImageMamba(channels=c)), # replace CA\u001b[39;00m\n\u001b[1;32m    124\u001b[0m         DualStreamBlock(CABlock(c)),\n\u001b[1;32m    125\u001b[0m         DualStreamBlock(nn\u001b[38;5;241m.\u001b[39mConv2d(c, c, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    126\u001b[0m     )\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma_l \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, c, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)), requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma_r \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, c, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)), requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/app/models/arch/dsrnet.py:93\u001b[0m, in \u001b[0;36mImageMamba.__init__\u001b[0;34m(self, channels, d_state, d_conv, expand)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, channels, d_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, d_conv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28msuper\u001b[39m(ImageMamba, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmamba_model \u001b[38;5;241m=\u001b[39m \u001b[43mMamba\u001b[49m( \u001b[38;5;66;03m# This module uses roughly 3 * expand * d_model^2 parameters\u001b[39;00m\n\u001b[1;32m     94\u001b[0m         d_model\u001b[38;5;241m=\u001b[39m channels, \u001b[38;5;66;03m# Model dimension d_model\u001b[39;00m\n\u001b[1;32m     95\u001b[0m         d_state\u001b[38;5;241m=\u001b[39md_state,  \u001b[38;5;66;03m# SSM state expansion factor\u001b[39;00m\n\u001b[1;32m     96\u001b[0m         d_conv\u001b[38;5;241m=\u001b[39md_conv,    \u001b[38;5;66;03m# Local convolution width\u001b[39;00m\n\u001b[1;32m     97\u001b[0m         expand\u001b[38;5;241m=\u001b[39mexpand,    \u001b[38;5;66;03m# Block expansion factor\u001b[39;00m\n\u001b[1;32m     98\u001b[0m         )\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels \u001b[38;5;241m=\u001b[39m channels\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Mamba' is not defined"
     ]
    }
   ],
   "source": [
    "%cd /app\n",
    "\n",
    "from models.arch.dsrnet import MuGIBlock, MuGIMBlock, ImageMamba\n",
    "import torch\n",
    "from mamba_ssm import Mamba\n",
    "m = MuGIBlock(3).to(\"cuda\")\n",
    "m2 = MuGIMBlock(3).to(\"cuda\")\n",
    "m1 = ImageMamba(3).to(\"cuda\")\n",
    "ma = Mamba(\n",
    "    # This module uses roughly 3 * expand * d_model^2 parameters\n",
    "            d_model=3, # Model dimension d_model\n",
    "            d_state=16,  # SSM state expansion factor\n",
    "            d_conv=4,    # Local convolution width\n",
    "            expand=2,    # Block expansion factor\n",
    "        ).to(\"cuda\")\n",
    "input = torch.rand((2, 3, 200, 200)).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([torch.Size([2, 3, 200, 200]), torch.Size([2, 3, 200, 200])],\n",
       " [torch.Size([2, 3, 200, 200])],\n",
       " [torch.Size([2, 3, 200, 200]), torch.Size([2, 3, 200, 200])])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.shape for x in m(input, input)],[m1(input).shape], [x.shape for x in m2(input, input)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 200, 200])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1(input).shape\n",
    "# x = input\n",
    "# batch_size, _, width, height = x.size()\n",
    "# x = x.permute(0, 2, 3, 1).contiguous().view(batch_size, -1, 3)\n",
    "# # x.shape\n",
    "# x = ma(x)\n",
    "# x.view(batch_size, width, height, -1).permute(0, 3, 1, 2).contiguous().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util.net_utils import count_parameters, count_conv_layers\n",
    "count_parameters(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 200, 200])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.chunk(2, dim=1)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c= 3\n",
    "count_parameters(torch.nn.Conv2d(c* 2, c * 2, 3, padding=1, groups=c*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13276390\n",
      "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "from models.arch.dsrnet import MDSRNet, DSRNet\n",
    "\n",
    "x = torch.ones(1, 3, 224, 224).cuda()\n",
    "feats = [\n",
    "    torch.ones(1, 64, 224, 224).cuda(),\n",
    "    torch.ones(1, 128, 112, 112).cuda(),\n",
    "    torch.ones(1, 256, 56, 56).cuda(),\n",
    "    torch.ones(1, 512, 28, 28).cuda(),\n",
    "    torch.ones(1, 512, 14, 14).cuda(),\n",
    "]\n",
    "\n",
    "enc_blks = [2, 2, 2]\n",
    "middle_blk_num = 4\n",
    "dec_blks = [2, 2, 2]\n",
    "model = MDSRNet(3, 3, width=32, middle_blk_num=middle_blk_num,\n",
    "                enc_blk_nums=enc_blks, dec_blk_nums=dec_blks).cuda()\n",
    "print(count_parameters(model))\n",
    "out_t, out_r, out_rr = model(x, feats)\n",
    "print(out_t.shape, out_r.shape, out_rr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util.net_utils import count_parameters, count_conv_layers # 396 (Mamba) -> 252 (d_state=8) ->\n",
    "from mamba_ssm import Mamba\n",
    "count_parameters(Mamba(\n",
    "    # This module uses roughly 3 * expand * d_model^2 parameters\n",
    "            d_model=3, # Model dimension d_model\n",
    "            d_state=8,  # SSM state expansion factor\n",
    "            d_conv=4,    # Local convolution width\n",
    "            expand=2,    # Block expansion factor\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app\n",
      "LICENSE      dataset\t\t models\t\t\t scripts.sh\tweights\n",
      "README.md    dummy.ipynb\t options\t\t test_sirs.py\n",
      "__pycache__  engine.py\t\t reflection-removal.zip  tools\n",
      "checkpoints  eval_sirs.py\t requirements.txt\t train_sirs.py\n",
      "data\t     mamba-container.sh  runner.sh\t\t util\n"
     ]
    }
   ],
   "source": [
    "%cd /app\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124602022\n",
      "118979238\n"
     ]
    }
   ],
   "source": [
    "from util.net_utils import count_parameters\n",
    "from models.arch.dsrnet import DSRNet, MDSRNet\n",
    "def dsrnet_l(in_channels=3, out_channels=3, width=64):\n",
    "    enc_blks = [2, 2, 4, 8]\n",
    "    middle_blk_num = 12\n",
    "    dec_blks = [2, 2, 2, 2]\n",
    "    # print(f\">>>>>>>>>>>{in_channels}, {out_channels}, {width}\")\n",
    "    return DSRNet(in_channels, out_channels, width=width,\n",
    "                  middle_blk_num=middle_blk_num,\n",
    "                  enc_blk_nums=enc_blks,\n",
    "                  dec_blk_nums=dec_blks,\n",
    "                  shared_b=True)\n",
    "\n",
    "def mdsrnet_l(in_channels=3, out_channels=3, width=64):\n",
    "    enc_blks = [2, 2, 2, 2]\n",
    "    middle_blk_num = 5\n",
    "    dec_blks = [2, 2, 2, 2]\n",
    "\n",
    "    return MDSRNet(in_channels, out_channels, width=width,\n",
    "                  middle_blk_num=middle_blk_num,\n",
    "                  enc_blk_nums=enc_blks,\n",
    "                  dec_blk_nums=dec_blks,\n",
    "                  shared_b=True)\n",
    "\n",
    "\n",
    "print(count_parameters(dsrnet_l()))\n",
    "print(count_parameters(mdsrnet_l()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
